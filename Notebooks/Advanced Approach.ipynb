{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70111c71ab9acab7",
   "metadata": {},
   "source": [
    "# YOLO for Detection\n",
    "For a more robust approach, we use a pre-trained YOLO model and fine-tune it for license plate detection.\n",
    "\n",
    "YOLO (You Only Look Once) and EfficientDet are object detection algorithms that can detect multiple objects in a single pass through the network, making them much faster and more efficient than traditional approaches. This implementation uses a pre-trained EfficientDet model from TensorFlow Hub.\n",
    "\n",
    "The advantages of this approach include:\n",
    "1. **Better accuracy**: These models are designed specifically for object detection and perform well on various object sizes\n",
    "2. **Speed**: They are optimized for efficient detection, making them suitable for real-time applications\n",
    "3. **Robustness**: They can handle multiple license plates in a single image\n",
    "\n",
    "To complete this implementation, you would need to:\n",
    "1. Filter the detection results to keep only license plates (likely by training the model to recognize the \"license plate\" class)\n",
    "2. Apply a confidence threshold to remove low-confidence detections\n",
    "3. Post-process the bounding boxes if needed (e.g., remove overlapping detections)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8bf6cec048ed63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\ULB\\MA1\\Proj\\PROJ-H419\\Car-plate-detection\\Notebooks\n",
      "Project root: c:\\ULB\\MA1\\Proj\\PROJ-H419\\Car-plate-detection\n",
      "Data path: c:\\ULB\\MA1\\Proj\\PROJ-H419\\Car-plate-detection\\Data\\Total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: C:\\ULB\\MA1\\Proj\\PROJ-H419\\proj-h419-lisence_plates_car_detection\\Code\\.venv\\Scripts\\python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     38\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip install ultralytics -q  # Use ultralytics for YOLOv8\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Import after installation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ultralytics'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Check if running in Colab or local\n",
    "import importlib.util\n",
    "IN_COLAB = importlib.util.find_spec(\"google.colab\") is not None\n",
    "\n",
    "# Set up paths similar to your previous notebook\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Add project root to path to ensure imports work correctly\n",
    "    project_root = os.path.join(current_dir, \"Car-plate-detection\")\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Project root added to path: {project_root}\")\n",
    "    DATA_PATH = Path(project_root+\"/Data/Total\")\n",
    "    print(DATA_PATH)\n",
    "else:\n",
    "    # If not in Colab, set the project root to the current working directory's parent\n",
    "    project_root = Path(os.getcwd()).parent\n",
    "    print(f\"Project root: {project_root}\")\n",
    "    DATA_PATH = project_root / \"Data\" / \"Total\"\n",
    "    print(f\"Data path: {DATA_PATH}\")\n",
    "\n",
    "# Install required packages for YOLO implementation\n",
    "!pip install ultralytics -q  # Use ultralytics for YOLOv8\n",
    "\n",
    "# Import after installation\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373e0718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMAGE_SIZE = (640, 640)  # Standard YOLO input size (larger than previous CNN)\n",
    "\n",
    "# Function to load dataset similar to the previous notebook\n",
    "def load_license_plate_dataset(data_path):\n",
    "    # Prepare a list to collect the dataset records\n",
    "    dataset = []\n",
    "\n",
    "    # Check if data_path exists\n",
    "    if not data_path.exists():\n",
    "        raise FileNotFoundError(f\"DATA_PATH does not exist: {data_path}\\n\"\n",
    "                                \"Please check the path or create the folder and add your data.\")\n",
    "\n",
    "    # Loop through all files in the folder\n",
    "    for file in data_path.iterdir():\n",
    "        if file.suffix == \".txt\":\n",
    "            try:\n",
    "                with open(file, 'r') as f:\n",
    "                    line = f.readline().strip()\n",
    "                    parts = line.split('\\t')\n",
    "\n",
    "                    if len(parts) != 6:\n",
    "                        print(f\"Skipping malformed file: {file.name}\")\n",
    "                        continue\n",
    "\n",
    "                    img_name, x, y, w, h, plate_text = parts\n",
    "                    img_path = data_path / img_name\n",
    "\n",
    "                    if not img_path.exists():\n",
    "                        print(f\"Image not found for annotation: {img_name}\")\n",
    "                        continue\n",
    "\n",
    "                    dataset.append({\n",
    "                        \"image_path\": str(img_path),\n",
    "                        \"x\": int(x),\n",
    "                        \"y\": int(y),\n",
    "                        \"w\": int(w),\n",
    "                        \"h\": int(h),\n",
    "                        \"plate_text\": plate_text\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(dataset)\n",
    "    print(f\"Loaded {len(df)} annotated images.\")\n",
    "    return df\n",
    "\n",
    "# Load the dataset\n",
    "df = load_license_plate_dataset(DATA_PATH)\n",
    "\n",
    "# Display a sample\n",
    "sample = df.iloc[random.randint(0, len(df)-1)]\n",
    "img = cv2.imread(sample[\"image_path\"])\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Draw bounding box\n",
    "x, y, w, h = sample[\"x\"], sample[\"y\"], sample[\"w\"], sample[\"h\"]\n",
    "cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(f\"Plate: {sample['plate_text']}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72271737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create YOLO compatible dataset structure\n",
    "def create_yolo_dataset(df, output_dir, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Create YOLO compatible dataset structure.\n",
    "    YOLO format expects:\n",
    "    - images/train, images/val folders for images\n",
    "    - labels/train, labels/val folders for labels\n",
    "    - Each label is a .txt file with format: class_id x_center y_center width height (normalized [0-1])\n",
    "    \"\"\"\n",
    "    # Create directory structure\n",
    "    output_path = Path(output_dir)\n",
    "    \n",
    "    # Create directories\n",
    "    (output_path / 'images' / 'train').mkdir(parents=True, exist_ok=True)\n",
    "    (output_path / 'images' / 'val').mkdir(parents=True, exist_ok=True)\n",
    "    (output_path / 'labels' / 'train').mkdir(parents=True, exist_ok=True)\n",
    "    (output_path / 'labels' / 'val').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Split the dataset\n",
    "    train_df, val_df = train_test_split(df, train_size=split_ratio, random_state=42)\n",
    "    \n",
    "    # Process training data\n",
    "    for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Processing training data\"):\n",
    "        process_yolo_sample(row, output_path / 'images' / 'train', output_path / 'labels' / 'train')\n",
    "    \n",
    "    # Process validation data\n",
    "    for idx, row in tqdm(val_df.iterrows(), total=len(val_df), desc=\"Processing validation data\"):\n",
    "        process_yolo_sample(row, output_path / 'images' / 'val', output_path / 'labels' / 'val')\n",
    "    \n",
    "    # Create dataset.yaml file for YOLO training\n",
    "    yaml_content = f\"\"\"path: {output_path.absolute()}  # dataset root dir\n",
    "train: images/train  # train images relative to path\n",
    "val: images/val  # val images relative to path\n",
    "\n",
    "nc: 1  # number of classes\n",
    "names: ['license_plate']  # class names\n",
    "\"\"\"\n",
    "    \n",
    "    with open(output_path / 'dataset.yaml', 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    print(f\"YOLO dataset created at {output_path.absolute()}\")\n",
    "    print(f\"Training samples: {len(train_df)}, Validation samples: {len(val_df)}\")\n",
    "    print(f\"Dataset config saved to {output_path / 'dataset.yaml'}\")\n",
    "    \n",
    "    return str(output_path / 'dataset.yaml')\n",
    "\n",
    "def process_yolo_sample(row, images_dir, labels_dir):\n",
    "    \"\"\"\n",
    "    Process a single sample to YOLO format.\n",
    "    \"\"\"\n",
    "    # Get image path and read image\n",
    "    img_path = Path(row[\"image_path\"])\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        print(f\"Could not read image at {img_path}\")\n",
    "        return\n",
    "    \n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    # Calculate normalized coordinates (center_x, center_y, width, height)\n",
    "    x_center = (row[\"x\"] + row[\"w\"] / 2) / width\n",
    "    y_center = (row[\"y\"] + row[\"h\"] / 2) / height\n",
    "    norm_width = row[\"w\"] / width\n",
    "    norm_height = row[\"h\"] / height\n",
    "    \n",
    "    # Clip values to ensure they're between 0 and 1\n",
    "    x_center = max(0, min(1, x_center))\n",
    "    y_center = max(0, min(1, y_center))\n",
    "    norm_width = max(0, min(1, norm_width))\n",
    "    norm_height = max(0, min(1, norm_height))\n",
    "    \n",
    "    # Create label file (class_id center_x center_y width height)\n",
    "    label_content = f\"0 {x_center} {y_center} {norm_width} {norm_height}\\n\"\n",
    "    \n",
    "    # Copy image to dataset folder\n",
    "    new_img_path = images_dir / img_path.name\n",
    "    cv2.imwrite(str(new_img_path), img)\n",
    "    \n",
    "    # Write label file\n",
    "    label_path = labels_dir / f\"{img_path.stem}.txt\"\n",
    "    with open(label_path, 'w') as f:\n",
    "        f.write(label_content)\n",
    "\n",
    "# Create a YOLO compatible dataset from our data\n",
    "yolo_dataset_path = create_yolo_dataset(df, os.path.join(project_root, \"yolo_dataset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c59a7b",
   "metadata": {},
   "source": [
    "# Step 2: YOLO Model Training and Fine-Tuning\n",
    "\n",
    "Now we'll use a pre-trained YOLO model and fine-tune it specifically for license plate detection. YOLOv8 is one of the latest and most performant object detection models available, and we'll leverage its power for our task.\n",
    "\n",
    "Key advantages of using YOLO over the custom CNN approach:\n",
    "\n",
    "1. **Transfer Learning**: Leverages knowledge from large-scale pre-training on diverse object categories\n",
    "2. **Better Feature Extraction**: Advanced backbone architecture designed specifically for object detection\n",
    "3. **Multiple Scale Detection**: Better detection of license plates regardless of size in the image\n",
    "4. **Robust to Occlusion**: Can detect partially visible license plates\n",
    "5. **Higher Precision**: Better localization of object boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the YOLO model\n",
    "def train_yolo_model(dataset_yaml, epochs=50):\n",
    "    \"\"\"\n",
    "    Train a YOLOv8 model for license plate detection.\n",
    "    \"\"\"\n",
    "    # Load a pre-trained YOLO model (n = nano, s = small, m = medium, l = large, x = extra large)\n",
    "    model = YOLO('yolov8n.pt')  # Start with smaller model for efficiency\n",
    "    \n",
    "    # Train the model\n",
    "    results = model.train(\n",
    "        data=dataset_yaml,\n",
    "        epochs=epochs,\n",
    "        imgsz=640,\n",
    "        batch=16,\n",
    "        patience=15,  # Early stopping patience\n",
    "        verbose=True,\n",
    "        device='0' if tf.test.is_gpu_available() else 'cpu',  # Use GPU if available\n",
    "        project=os.path.join(project_root, \"yolo_runs\"),\n",
    "        name=\"license_plate_detector\",\n",
    "        pretrained=True,\n",
    "        optimizer=\"Adam\",\n",
    "        lr0=0.001,\n",
    "        lrf=0.01,\n",
    "        save=True,\n",
    "        plots=True  # Generate training plots\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "try:\n",
    "    print(\"Starting YOLOv8 training...\")\n",
    "    yolo_model = train_yolo_model(yolo_dataset_path, epochs=30)\n",
    "    print(\"Training complete!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab37f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate YOLO model\n",
    "def evaluate_yolo_model(model, validation_folder):\n",
    "    \"\"\"\n",
    "    Evaluate the YOLO model on the validation set.\n",
    "    \"\"\"\n",
    "    # Run validation\n",
    "    val_results = model.val(data=validation_folder)\n",
    "    \n",
    "    # Extract metrics\n",
    "    metrics = val_results.box.metrics.dict\n",
    "    print(f\"mAP50: {metrics['map50']:.4f}\")\n",
    "    print(f\"mAP50-95: {metrics['map']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Run evaluation\n",
    "print(\"Evaluating model...\")\n",
    "eval_metrics = evaluate_yolo_model(yolo_model, yolo_dataset_path)\n",
    "\n",
    "# Function to calculate IoU same as in your previous notebook\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate IoU between two boxes [x1, y1, x2, y2] format\n",
    "    \"\"\"\n",
    "    # Extract coordinates\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "    \n",
    "    # Calculate intersection area\n",
    "    x1_i = max(x1_1, x1_2)\n",
    "    y1_i = max(y1_1, y1_2)\n",
    "    x2_i = min(x2_1, x2_2)\n",
    "    y2_i = min(y2_1, y2_2)\n",
    "    \n",
    "    if x2_i < x1_i or y2_i < y1_i:\n",
    "        return 0.0\n",
    "    \n",
    "    intersection_area = (x2_i - x1_i) * (y2_i - y1_i)\n",
    "    \n",
    "    # Calculate union area\n",
    "    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / union_area if union_area > 0 else 0\n",
    "    \n",
    "    return iou\n",
    "\n",
    "# Function to detect license plates in new images (similar to what you had before)\n",
    "def detect_license_plate_yolo(model, image_path, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Detect license plates in an image using the fine-tuned YOLO model.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Could not read image at {image_path}\")\n",
    "        return None, []\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Run inference\n",
    "    results = model.predict(img_rgb, conf=conf_threshold, verbose=False)[0]\n",
    "    \n",
    "    # Get detection boxes\n",
    "    boxes = results.boxes.xyxy.cpu().numpy()  # Get boxes in [x1, y1, x2, y2] format\n",
    "    confidences = results.boxes.conf.cpu().numpy()\n",
    "    \n",
    "    # Draw results on image\n",
    "    result_img = img_rgb.copy()\n",
    "    for i, box in enumerate(boxes):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        confidence = confidences[i]\n",
    "        \n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(result_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Add confidence text\n",
    "        cv2.putText(result_img, f\"{confidence:.2f}\", (x1, y1-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    return result_img, boxes, confidences\n",
    "\n",
    "# Test the detector on a few images\n",
    "def test_detection_on_samples(model, df, num_samples=5):\n",
    "    \"\"\"\n",
    "    Test the YOLO detector on random samples and show results\n",
    "    \"\"\"\n",
    "    # Get random samples\n",
    "    sample_indices = random.sample(range(len(df)), num_samples)\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        row = df.iloc[idx]\n",
    "        img_path = row[\"image_path\"]\n",
    "        \n",
    "        # Ground truth box (x1, y1, x2, y2 format)\n",
    "        true_box = [row[\"x\"], row[\"y\"], row[\"x\"] + row[\"w\"], row[\"y\"] + row[\"h\"]]\n",
    "        \n",
    "        # Run detection\n",
    "        result_img, pred_boxes, confidences = detect_license_plate_yolo(model, img_path)\n",
    "        \n",
    "        # Calculate IoU if any detection is found\n",
    "        iou_value = 0\n",
    "        if len(pred_boxes) > 0:\n",
    "            # Get the box with highest confidence\n",
    "            best_box = pred_boxes[np.argmax(confidences)]\n",
    "            iou_value = calculate_iou(true_box, best_box)\n",
    "        \n",
    "        # Show result\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(result_img)\n",
    "        plt.title(f\"IoU: {iou_value:.4f}, Plate: {row['plate_text']}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Test the detector\n",
    "print(\"Testing detection on sample images...\")\n",
    "test_detection_on_samples(yolo_model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive evaluation to match the metrics used in your previous model\n",
    "def evaluate_license_plate_detection_yolo(model, df, num_samples=5):\n",
    "    \"\"\"\n",
    "    Evaluate YOLO model on the dataset with metrics matching the previous approach\n",
    "    \"\"\"\n",
    "    # Calculate IoU for all samples in the dataset\n",
    "    iou_values = []\n",
    "    pred_boxes_list = []\n",
    "    confidences_list = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Evaluating model\"):\n",
    "        img_path = row[\"image_path\"]\n",
    "        \n",
    "        # Ground truth box (x1, y1, x2, y2 format)\n",
    "        true_box = [row[\"x\"], row[\"y\"], row[\"x\"] + row[\"w\"], row[\"y\"] + row[\"h\"]]\n",
    "        \n",
    "        # Run detection\n",
    "        _, pred_boxes, confidences = detect_license_plate_yolo(model, img_path)\n",
    "        \n",
    "        # Calculate IoU if any detection is found\n",
    "        if len(pred_boxes) > 0:\n",
    "            # Get the box with highest confidence\n",
    "            best_pred_idx = np.argmax(confidences)\n",
    "            best_box = pred_boxes[best_pred_idx]\n",
    "            best_conf = confidences[best_pred_idx]\n",
    "            \n",
    "            iou = calculate_iou(true_box, best_box)\n",
    "            iou_values.append(iou)\n",
    "            pred_boxes_list.append(best_box)\n",
    "            confidences_list.append(best_conf)\n",
    "        else:\n",
    "            # No detection\n",
    "            iou_values.append(0.0)\n",
    "            pred_boxes_list.append([0, 0, 0, 0])\n",
    "            confidences_list.append(0.0)\n",
    "    \n",
    "    # Find best and worst predictions\n",
    "    iou_indices = np.argsort(iou_values)\n",
    "    worst_indices = iou_indices[:num_samples//2]\n",
    "    best_indices = iou_indices[-num_samples//2:]\n",
    "    \n",
    "    # Visualization of best and worst cases\n",
    "    plt.figure(figsize=(15, 4*num_samples))\n",
    "    \n",
    "    samples_to_show = np.concatenate([worst_indices, best_indices])\n",
    "    \n",
    "    for i, idx in enumerate(samples_to_show):\n",
    "        row = df.iloc[idx]\n",
    "        img_path = row[\"image_path\"]\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Draw ground truth (green)\n",
    "        x, y, w, h = row[\"x\"], row[\"y\"], row[\"w\"], row[\"h\"]\n",
    "        cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw prediction (red) if available\n",
    "        if len(pred_boxes_list) > idx:\n",
    "            pred_box = pred_boxes_list[idx]\n",
    "            if not np.all(pred_box == 0):\n",
    "                x1, y1, x2, y2 = map(int, pred_box)\n",
    "                cv2.rectangle(img_rgb, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        \n",
    "        plt.subplot(num_samples, 2, i+1)\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.title(f\"IoU: {iou_values[idx]:.4f} {'(Worst)' if idx in worst_indices else '(Best)'}\", fontsize=10)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate area of each license plate for size categorization\n",
    "    def calculate_normalized_area(row):\n",
    "        # Get image dimensions\n",
    "        img = cv2.imread(row[\"image_path\"])\n",
    "        if img is None:\n",
    "            return 0\n",
    "        \n",
    "        h, w = img.shape[:2]\n",
    "        # Calculate normalized area\n",
    "        return (row[\"w\"] * row[\"h\"]) / (w * h)\n",
    "    \n",
    "    # Get normalized areas\n",
    "    areas = [calculate_normalized_area(df.iloc[i]) for i in range(len(df))]\n",
    "    \n",
    "    # Define thresholds (matching your previous notebook)\n",
    "    small_threshold = 0.03\n",
    "    large_threshold = 0.1\n",
    "    \n",
    "    # Categorize plates\n",
    "    size_categories = []\n",
    "    for area in areas:\n",
    "        if area < small_threshold:\n",
    "            size_categories.append(0)  # Small\n",
    "        elif area > large_threshold:\n",
    "            size_categories.append(2)  # Large\n",
    "        else:\n",
    "            size_categories.append(1)  # Medium\n",
    "    \n",
    "    # Group by plate size\n",
    "    small_ious = [iou for iou, cat in zip(iou_values, size_categories) if cat == 0]\n",
    "    medium_ious = [iou for iou, cat in zip(iou_values, size_categories) if cat == 1]\n",
    "    large_ious = [iou for iou, cat in zip(iou_values, size_categories) if cat == 2]\n",
    "    \n",
    "    # Print statistics (same format as your previous notebook)\n",
    "    print(\"Overall Performance:\")\n",
    "    print(f\"Average IoU: {np.mean(iou_values):.4f}\")\n",
    "    print(f\"Median IoU: {np.median(iou_values):.4f}\")\n",
    "    print(f\"Min IoU: {np.min(iou_values):.4f}\")\n",
    "    print(f\"Max IoU: {np.max(iou_values):.4f}\")\n",
    "    print(\"\\nPerformance by Plate Size:\")\n",
    "    print(f\"Small Plates: Avg IoU = {np.mean(small_ious) if small_ious else 0:.4f}, Count = {len(small_ious)}\")\n",
    "    print(f\"Medium Plates: Avg IoU = {np.mean(medium_ious) if medium_ious else 0:.4f}, Count = {len(medium_ious)}\")\n",
    "    print(f\"Large Plates: Avg IoU = {np.mean(large_ious) if large_ious else 0:.4f}, Count = {len(large_ious)}\")\n",
    "    \n",
    "    # Plot IoU distribution (same format as your previous notebook)\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Histogram of IoU values\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(iou_values, bins=20, alpha=0.7, color='blue')\n",
    "    plt.axvline(np.mean(iou_values), color='red', linestyle='dashed', linewidth=2, label=f'Mean IoU: {np.mean(iou_values):.4f}')\n",
    "    plt.axvline(np.median(iou_values), color='green', linestyle='dashed', linewidth=2, label=f'Median IoU: {np.median(iou_values):.4f}')\n",
    "    plt.title('IoU Distribution')\n",
    "    plt.xlabel('IoU Value')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    \n",
    "    # IoU by plate size\n",
    "    plt.subplot(1, 2, 2)\n",
    "    boxplot_data = [small_ious, medium_ious, large_ious]\n",
    "    plt.boxplot(boxplot_data, labels=['Small', 'Medium', 'Large'])\n",
    "    plt.title('IoU by License Plate Size')\n",
    "    plt.ylabel('IoU Value')\n",
    "    plt.xlabel('Plate Size')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return iou_values\n",
    "\n",
    "# Evaluate on a subset for performance\n",
    "test_df = df.sample(n=min(100, len(df)), random_state=42)\n",
    "print(\"Running comprehensive evaluation...\")\n",
    "iou_values = evaluate_license_plate_detection_yolo(yolo_model, test_df, num_samples=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28933c93",
   "metadata": {},
   "source": [
    "# Comparing YOLO vs. Custom CNN Results\n",
    "\n",
    "The above results from the YOLO-based model can be directly compared with your previous custom CNN approach. YOLO typically provides significant improvements due to several factors:\n",
    "\n",
    "1. **Better Feature Extraction**: YOLO uses a more sophisticated backbone network pre-trained on millions of images\n",
    "\n",
    "2. **Scale Invariance**: YOLO's feature pyramid design helps it detect license plates of varying sizes\n",
    "\n",
    "3. **Contextual Understanding**: YOLO can use surrounding vehicle information to better locate license plates\n",
    "\n",
    "4. **Robustness**: Better handling of challenging conditions like poor lighting and partial occlusion\n",
    "\n",
    "5. **Confidence Scores**: YOLO provides detection confidence, allowing you to filter unreliable detections\n",
    "\n",
    "The metrics we used for evaluation are directly comparable to your previous approach, making it easy to quantify the improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbabb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for real-world license plate detection\n",
    "def detect_and_extract_license_plate(model, image_path, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Complete function to detect and extract license plates from an image.\n",
    "    Returns the cropped license plate region for further processing.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Could not read image at {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Run inference\n",
    "    results = model.predict(img_rgb, conf=conf_threshold, verbose=False)[0]\n",
    "    \n",
    "    # Get detection boxes and confidences\n",
    "    boxes = results.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2] format\n",
    "    confidences = results.boxes.conf.cpu().numpy()\n",
    "    \n",
    "    if len(boxes) == 0:\n",
    "        print(\"No license plate detected\")\n",
    "        return img_rgb, None\n",
    "    \n",
    "    # Get the highest confidence detection\n",
    "    best_idx = np.argmax(confidences)\n",
    "    best_box = boxes[best_idx]\n",
    "    best_conf = confidences[best_idx]\n",
    "    \n",
    "    # Extract coordinates\n",
    "    x1, y1, x2, y2 = map(int, best_box)\n",
    "    \n",
    "    # Draw on image\n",
    "    result_img = img_rgb.copy()\n",
    "    cv2.rectangle(result_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(result_img, f\"{best_conf:.2f}\", (x1, y1-10),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Extract the plate region\n",
    "    plate_region = img_rgb[y1:y2, x1:x2]\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(result_img)\n",
    "    plt.title(f\"License Plate Detection (Conf: {best_conf:.2f})\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(plate_region)\n",
    "    plt.title(\"Extracted License Plate\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return result_img, plate_region\n",
    "\n",
    "# Test the complete detection pipeline on a few images\n",
    "test_images = random.sample(list(df[\"image_path\"]), 3)\n",
    "\n",
    "for img_path in test_images:\n",
    "    print(f\"\\nProcessing image: {os.path.basename(img_path)}\")\n",
    "    _, plate = detect_and_extract_license_plate(yolo_model, img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
