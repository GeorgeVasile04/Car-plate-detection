{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "658a806e",
   "metadata": {},
   "source": [
    "# Modular License Plate Detection\n",
    "\n",
    "This notebook demonstrates how to use the modular license plate detection framework. The code has been reorganized into a structured package to improve maintainability, reusability, and extensibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e22aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "\n",
    "# Add project root to path to enable imports\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import our modules\n",
    "from license_plate_detection.data.loader import get_data_path, load_dataset, preprocess_dataset, split_dataset\n",
    "from license_plate_detection.data.augmentation import augment_data, visualize_augmentation\n",
    "from license_plate_detection.models.detector import create_license_plate_detector, create_enhanced_license_plate_detector\n",
    "from license_plate_detection.models.losses import enhanced_iou_metric, combined_detection_loss, giou_loss\n",
    "from license_plate_detection.train.trainer import train_model, save_model\n",
    "from license_plate_detection.train.scheduler import CosineAnnealingWarmRestarts\n",
    "from license_plate_detection.evaluation.evaluator import evaluate_license_plate_detection, evaluate_model_comprehensive\n",
    "from license_plate_detection.utils.visualization import visualize_training_history, visualize_model_summary\n",
    "from license_plate_detection.utils.analysis import analyze_error_patterns\n",
    "from license_plate_detection.main import detect_license_plate, load_and_prepare_model\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa73039",
   "metadata": {},
   "source": [
    "## 1. Dataset Loading and Preprocessing\n",
    "\n",
    "First, we'll load and preprocess the dataset using our modular functions. The data loading is now handled by dedicated functions that can work with various annotation formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6878a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths to dataset\n",
    "data_path = get_data_path()\n",
    "IMAGES_PATH = data_path / \"images\"\n",
    "ANNOTATIONS_PATH = data_path / \"annotations\"\n",
    "\n",
    "print(f\"Data path: {data_path}\")\n",
    "print(f\"Images directory: {IMAGES_PATH}\")\n",
    "print(f\"Annotations directory: {ANNOTATIONS_PATH}\")\n",
    "\n",
    "# Load the dataset\n",
    "df = load_dataset(ANNOTATIONS_PATH, IMAGES_PATH)\n",
    "print(f\"Loaded {len(df)} annotated images.\")\n",
    "\n",
    "# Show sample data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a102ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample image from the dataset\n",
    "if len(df) > 0:\n",
    "    # Take a specific sample or a random one\n",
    "    sample_idx = min(42, len(df) - 1)  # Ensure index exists\n",
    "    sample = df.iloc[sample_idx]\n",
    "    \n",
    "    # Load the image\n",
    "    img = cv2.imread(sample[\"image_path\"])\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Draw bounding box\n",
    "    x, y, w, h = sample[\"x\"], sample[\"y\"], sample[\"w\"], sample[\"h\"]\n",
    "    cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img_rgb)\n",
    "    if \"plate_text\" in sample and sample[\"plate_text\"] != \"Unknown\":\n",
    "        plt.title(f\"Plate: {sample['plate_text']}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No images loaded. Please check dataset path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a1515c",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "Now we'll preprocess the dataset by resizing images and normalizing bounding box coordinates. This is handled by the `preprocess_dataset` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "IMAGE_SIZE = (224, 224)  # Target size for CNN\n",
    "X, y = preprocess_dataset(df, image_size=IMAGE_SIZE)\n",
    "\n",
    "print(f\"Processed {len(X)} images.\")\n",
    "print(\"Image shape:\", X[0].shape)\n",
    "print(\"Sample bounding box (normalized):\", y[0])\n",
    "\n",
    "# Visualize a processed sample to see the difference between an original and preprocessed image\n",
    "def visualize_processed_sample(index=0):\n",
    "    if index >= len(X) or index < 0:\n",
    "        print(f\"Index {index} is out of bounds.\")\n",
    "        return\n",
    "        \n",
    "    img_normalized = X[index]\n",
    "    bbox_norm = y[index]\n",
    "    original_row = df.iloc[index]\n",
    "    \n",
    "    # Load the original image\n",
    "    img_original = cv2.imread(original_row[\"image_path\"])\n",
    "    img_original = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Draw original bbox\n",
    "    x_orig, y_orig, w_orig, h_orig = original_row[\"x\"], original_row[\"y\"], original_row[\"w\"], original_row[\"h\"]\n",
    "    img_original_vis = img_original.copy()\n",
    "    cv2.rectangle(img_original_vis, (x_orig, y_orig), (x_orig + w_orig, y_orig + h_orig), (255, 0, 0), 2)\n",
    "    \n",
    "    # Prepare normalized image\n",
    "    img_vis = (img_normalized * 255).astype(np.uint8).copy()\n",
    "    x_norm = int(bbox_norm[0] * IMAGE_SIZE[0])\n",
    "    y_norm = int(bbox_norm[1] * IMAGE_SIZE[1])\n",
    "    w_norm = int(bbox_norm[2] * IMAGE_SIZE[0])\n",
    "    h_norm = int(bbox_norm[3] * IMAGE_SIZE[1])\n",
    "    cv2.rectangle(img_vis, (x_norm, y_norm), (x_norm + w_norm, y_norm + h_norm), (0, 255, 0), 2)\n",
    "    \n",
    "    # Plot side-by-side\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    axs[0].imshow(img_original_vis)\n",
    "    axs[0].set_title('Original Image with Original BBox')\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    axs[1].imshow(img_vis)\n",
    "    axs[1].set_title('Normalized & Resized Image with BBox')\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show a processed sample\n",
    "visualize_processed_sample(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef0a48b",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation\n",
    "\n",
    "To improve model generalization, we'll use data augmentation techniques. The augmentation module provides functions to apply various transformations to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data augmentation\n",
    "X_aug, y_aug = augment_data(X, y, augmentation_factor=1)\n",
    "\n",
    "# Visualize some augmented samples\n",
    "visualize_augmentation(X, y, X_aug, y_aug, num_samples=2)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = split_dataset(X_aug, y_aug, test_size=0.2, random_state=42)\n",
    "print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0811527",
   "metadata": {},
   "source": [
    "## 4. Model Architecture\n",
    "\n",
    "Now we'll create our license plate detection model. We'll use the enhanced model architecture for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78416db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the enhanced model\n",
    "model = create_enhanced_license_plate_detector(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# Print model size information\n",
    "trainable_count = np.sum([keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "non_trainable_count = np.sum([keras.backend.count_params(w) for w in model.non_trainable_weights])\n",
    "print(f'Total parameters: {trainable_count + non_trainable_count:,}')\n",
    "print(f'Trainable parameters: {trainable_count:,}')\n",
    "print(f'Non-trainable parameters: {non_trainable_count:,}')\n",
    "\n",
    "# Visualize model architecture (optional)\n",
    "# visualize_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6d4fbb",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "Now we'll train the model using our custom loss functions and learning rate scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3aa0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=combined_detection_loss,\n",
    "    metrics=[enhanced_iou_metric, giou_loss]\n",
    ")\n",
    "\n",
    "# Create callbacks\n",
    "callbacks = [\n",
    "    # Learning rate scheduler\n",
    "    CosineAnnealingWarmRestarts(\n",
    "        initial_lr=0.001,\n",
    "        min_lr=1e-6,\n",
    "        cycles=5,\n",
    "        cycle_length=10\n",
    "    ),\n",
    "    \n",
    "    # Early stopping\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_enhanced_iou_metric',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        mode='max'\n",
    "    ),\n",
    "    \n",
    "    # Model checkpoint\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'enhanced_license_plate_detector.h5',\n",
    "        monitor='val_enhanced_iou_metric',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train model (commented out to avoid accidental training)\n",
    "\"\"\"\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Visualize training history\n",
    "visualize_training_history(history)\n",
    "\n",
    "# Save model\n",
    "save_model(model, 'license_plate_detector_final.h5')\n",
    "\"\"\"\n",
    "\n",
    "# Alternatively, we can use the train_model function from our module\n",
    "\"\"\"\n",
    "history, model = train_model(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    loss_function=combined_detection_loss,\n",
    "    metrics=[enhanced_iou_metric],\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a140b6",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "Let's evaluate our model using different evaluation functions. If you don't have a trained model yet,\n",
    "you can load a pre-trained model or use the following code to generate some sample predictions for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfdc788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration purposes, we'll use the untrained model to generate random predictions\n",
    "# In a real scenario, you would load a trained model\n",
    "\n",
    "# Option 1: Load a pre-trained model if available\n",
    "\"\"\"\n",
    "model = load_and_prepare_model('license_plate_detector.h5')\n",
    "\"\"\"\n",
    "\n",
    "# Option 2: For demo purposes, use the untrained model with random but plausible predictions\n",
    "def generate_demo_predictions(model, X_val, y_val):\n",
    "    \"\"\"Generate plausible demo predictions for visualization purposes\"\"\"\n",
    "    # Get predictions from untrained model\n",
    "    random_preds = model.predict(X_val)\n",
    "    \n",
    "    # Make them somewhat reasonable by combining with ground truth\n",
    "    demo_preds = []\n",
    "    for i, (pred, gt) in enumerate(zip(random_preds, y_val)):\n",
    "        # Create a prediction that's a noisy version of ground truth\n",
    "        noise = np.random.normal(0, 0.1, 4)  # Add some noise\n",
    "        noisy_pred = gt + noise\n",
    "        \n",
    "        # Ensure values are in range [0, 1]\n",
    "        noisy_pred = np.clip(noisy_pred, 0, 1)\n",
    "        \n",
    "        # Make width and height reasonable\n",
    "        noisy_pred[2] = max(0.05, min(noisy_pred[2], 0.5))  # Width\n",
    "        noisy_pred[3] = max(0.05, min(noisy_pred[3], 0.3))  # Height\n",
    "        \n",
    "        demo_preds.append(noisy_pred)\n",
    "    \n",
    "    return np.array(demo_preds)\n",
    "\n",
    "# Generate demo predictions\n",
    "demo_predictions = generate_demo_predictions(model, X_val, y_val)\n",
    "\n",
    "# Basic evaluation with visualization\n",
    "def evaluate_with_demo_predictions(X_val, y_val, y_pred):\n",
    "    \"\"\"Wrapper to evaluate with provided predictions\"\"\"\n",
    "    # Modified version of evaluate_license_plate_detection that accepts y_pred directly\n",
    "    iou_values = []\n",
    "    confidences_list = []  # For consistency with original function\n",
    "    \n",
    "    for i in range(len(y_val)):\n",
    "        true_bbox = y_val[i]\n",
    "        pred_bbox = y_pred[i]\n",
    "        \n",
    "        # Convert to x1, y1, x2, y2 format\n",
    "        x1_true, y1_true = true_bbox[0], true_bbox[1]\n",
    "        x2_true, y2_true = x1_true + true_bbox[2], y1_true + true_bbox[3]\n",
    "\n",
    "        x1_pred, y1_pred = pred_bbox[0], pred_bbox[1]\n",
    "        x2_pred, y2_pred = x1_pred + pred_bbox[2], y1_pred + pred_bbox[3]\n",
    "        \n",
    "        # Calculate intersection\n",
    "        x1_inter = max(x1_true, x1_pred)\n",
    "        y1_inter = max(y1_true, y1_pred)\n",
    "        x2_inter = min(x2_true, x2_pred)\n",
    "        y2_inter = min(y2_true, y2_pred)\n",
    "        \n",
    "        # Calculate areas\n",
    "        w_intersect = max(0, x2_inter - x1_inter)\n",
    "        h_intersect = max(0, y2_inter - y1_inter)\n",
    "        area_intersect = w_intersect * h_intersect\n",
    "        \n",
    "        area_true = true_bbox[2] * true_bbox[3]\n",
    "        area_pred = pred_bbox[2] * pred_bbox[3]\n",
    "        area_union = area_true + area_pred - area_intersect\n",
    "        \n",
    "        # IoU\n",
    "        iou = area_intersect / area_union if area_union > 0 else 0\n",
    "        iou_values.append(iou)\n",
    "        \n",
    "        # Dummy confidence value for visualization\n",
    "        confidences_list.append(0.8 + 0.2 * np.random.random())\n",
    "    \n",
    "    # Find best and worst predictions\n",
    "    num_samples = 4  # Number of samples to visualize\n",
    "    iou_indices = np.argsort(iou_values)\n",
    "    worst_indices = iou_indices[:num_samples//2]\n",
    "    best_indices = iou_indices[-num_samples//2:]\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(15, 4*num_samples))\n",
    "    \n",
    "    samples_to_show = np.concatenate([worst_indices, best_indices])\n",
    "    \n",
    "    for i, idx in enumerate(samples_to_show):\n",
    "        img = X_val[idx]\n",
    "        true_bbox = y_val[idx]\n",
    "        pred_bbox = y_pred[idx]\n",
    "        \n",
    "        # Display image with both bounding boxes\n",
    "        img_display = (img * 255).astype(np.uint8).copy()\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # True bbox (green)\n",
    "        x, y = int(true_bbox[0] * w), int(true_bbox[1] * h)\n",
    "        bbox_w, bbox_h = int(true_bbox[2] * w), int(true_bbox[3] * h)\n",
    "        cv2.rectangle(img_display, (x, y), (x + bbox_w, y + bbox_h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Pred bbox (red)\n",
    "        x, y = int(pred_bbox[0] * w), int(pred_bbox[1] * h)\n",
    "        bbox_w, bbox_h = int(pred_bbox[2] * w), int(pred_bbox[3] * h)\n",
    "        cv2.rectangle(img_display, (x, y), (x + bbox_w, y + bbox_h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Add confidence text\n",
    "        confidence = confidences_list[idx]\n",
    "        cv2.putText(img_display, f\"{confidence:.2f}\", (x, y-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        \n",
    "        plt.subplot(num_samples, 2, i+1)\n",
    "        plt.imshow(img_display)\n",
    "        plt.title(f\"IoU: {iou_values[idx]:.4f} {'(Worst)' if idx in worst_indices else '(Best)'}\", fontsize=10)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"Overall Performance:\")\n",
    "    print(f\"Average IoU: {np.mean(iou_values):.4f}\")\n",
    "    print(f\"Median IoU: {np.median(iou_values):.4f}\")\n",
    "    print(f\"Min IoU: {np.min(iou_values):.4f}\")\n",
    "    print(f\"Max IoU: {np.max(iou_values):.4f}\")\n",
    "    \n",
    "    return iou_values\n",
    "\n",
    "# Run evaluation with demo predictions\n",
    "iou_values = evaluate_with_demo_predictions(X_val, y_val, demo_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7205ca",
   "metadata": {},
   "source": [
    "## 7. Error Analysis\n",
    "\n",
    "Now we'll analyze the error patterns to understand where the model struggles and identify opportunities for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze error patterns with demo predictions\n",
    "def analyze_error_patterns_with_demo_predictions(X_val, y_val, y_pred, plate_sizes=None):\n",
    "    \"\"\"Modified version of analyze_error_patterns that accepts y_pred directly\"\"\"\n",
    "    print(\"Analyzing error patterns...\")\n",
    "    \n",
    "    # If plate sizes not provided, calculate them\n",
    "    if plate_sizes is None:\n",
    "        plate_sizes = [box[2] * box[3] for box in y_val]\n",
    "    \n",
    "    # Calculate errors and IoU\n",
    "    iou_values = []\n",
    "    x_errors = []\n",
    "    y_errors = []\n",
    "    w_errors = []\n",
    "    h_errors = []\n",
    "    center_errors = []\n",
    "    area_errors = []\n",
    "    \n",
    "    for i in range(len(y_val)):\n",
    "        true_box = y_val[i]\n",
    "        pred_box = y_pred[i]\n",
    "        \n",
    "        # Basic coordinate errors\n",
    "        x_errors.append(abs(true_box[0] - pred_box[0]))\n",
    "        y_errors.append(abs(true_box[1] - pred_box[1]))\n",
    "        w_errors.append(abs(true_box[2] - pred_box[2]))\n",
    "        h_errors.append(abs(true_box[3] - pred_box[3]))\n",
    "        \n",
    "        # Center point error\n",
    "        true_center_x = true_box[0] + true_box[2]/2\n",
    "        true_center_y = true_box[1] + true_box[3]/2\n",
    "        pred_center_x = pred_box[0] + pred_box[2]/2\n",
    "        pred_center_y = pred_box[1] + pred_box[3]/2\n",
    "        center_errors.append(np.sqrt((true_center_x - pred_center_x)**2 + \n",
    "                                    (true_center_y - pred_center_y)**2))\n",
    "        \n",
    "        # Area error\n",
    "        true_area = true_box[2] * true_box[3]\n",
    "        pred_area = pred_box[2] * pred_box[3]\n",
    "        area_errors.append(abs(true_area - pred_area) / true_area)\n",
    "        \n",
    "        # Calculate IoU\n",
    "        # Convert to x1, y1, x2, y2 format\n",
    "        x1_true, y1_true = true_box[0], true_box[1]\n",
    "        x2_true, y2_true = x1_true + true_box[2], y1_true + true_box[3]\n",
    "\n",
    "        x1_pred, y1_pred = pred_box[0], pred_box[1]\n",
    "        x2_pred, y2_pred = x1_pred + pred_box[2], y1_pred + pred_box[3]\n",
    "        \n",
    "        # Calculate intersection\n",
    "        x1_inter = max(x1_true, x1_pred)\n",
    "        y1_inter = max(y1_true, y1_pred)\n",
    "        x2_inter = min(x2_true, x2_pred)\n",
    "        y2_inter = min(y2_true, y2_pred)\n",
    "        \n",
    "        # Calculate areas\n",
    "        w_intersect = max(0, x2_inter - x1_inter)\n",
    "        h_intersect = max(0, y2_inter - y1_inter)\n",
    "        area_intersect = w_intersect * h_intersect\n",
    "        \n",
    "        area_true = true_box[2] * true_box[3]\n",
    "        area_pred = pred_box[2] * pred_box[3]\n",
    "        area_union = area_true + area_pred - area_intersect\n",
    "        \n",
    "        # IoU\n",
    "        iou = area_intersect / area_union if area_union > 0 else 0\n",
    "        iou_values.append(iou)\n",
    "    \n",
    "    # Characterize plates by size\n",
    "    small_threshold = 0.03\n",
    "    large_threshold = 0.1\n",
    "    \n",
    "    small_indices = [i for i, size in enumerate(plate_sizes) if size < small_threshold]\n",
    "    medium_indices = [i for i, size in enumerate(plate_sizes) if small_threshold <= size <= large_threshold]\n",
    "    large_indices = [i for i, size in enumerate(plate_sizes) if size > large_threshold]\n",
    "    \n",
    "    # Calculate error metrics by plate size\n",
    "    def get_metrics_by_indices(indices, name):\n",
    "        if not indices:\n",
    "            print(f\"No {name} plates found\")\n",
    "            return None\n",
    "            \n",
    "        size_iou = [iou_values[i] for i in indices]\n",
    "        size_x_err = [x_errors[i] for i in indices]\n",
    "        size_y_err = [y_errors[i] for i in indices]\n",
    "        size_w_err = [w_errors[i] for i in indices]\n",
    "        size_h_err = [h_errors[i] for i in indices]\n",
    "        size_center_err = [center_errors[i] for i in indices]\n",
    "        size_area_err = [area_errors[i] for i in indices]\n",
    "        \n",
    "        print(f\"\\n{name} Plates (n={len(indices)}):\")\n",
    "        print(f\"  Mean IoU: {np.mean(size_iou):.4f}\")\n",
    "        print(f\"  Center Error: {np.mean(size_center_err):.4f}\")\n",
    "        print(f\"  Area Error: {np.mean(size_area_err):.4f}\")\n",
    "        print(f\"  X Error: {np.mean(size_x_err):.4f}, Y Error: {np.mean(size_y_err):.4f}\")\n",
    "        print(f\"  Width Error: {np.mean(size_w_err):.4f}, Height Error: {np.mean(size_h_err):.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'mean_iou': np.mean(size_iou),\n",
    "            'center_error': np.mean(size_center_err),\n",
    "            'area_error': np.mean(size_area_err),\n",
    "            'x_error': np.mean(size_x_err),\n",
    "            'y_error': np.mean(size_y_err),\n",
    "            'w_error': np.mean(size_w_err),\n",
    "            'h_error': np.mean(size_h_err)\n",
    "        }\n",
    "    \n",
    "    # Get metrics by plate size\n",
    "    small_metrics = get_metrics_by_indices(small_indices, \"Small\")\n",
    "    medium_metrics = get_metrics_by_indices(medium_indices, \"Medium\")\n",
    "    large_metrics = get_metrics_by_indices(large_indices, \"Large\")\n",
    "    \n",
    "    # Create visualizations (can be added based on the original function)\n",
    "    \n",
    "    # Return results for potential further use\n",
    "    return {\n",
    "        'iou_values': iou_values,\n",
    "        'x_errors': x_errors,\n",
    "        'y_errors': y_errors,\n",
    "        'w_errors': w_errors,\n",
    "        'h_errors': h_errors,\n",
    "        'center_errors': center_errors,\n",
    "        'area_errors': area_errors,\n",
    "        'small_metrics': small_metrics,\n",
    "        'medium_metrics': medium_metrics,\n",
    "        'large_metrics': large_metrics\n",
    "    }\n",
    "\n",
    "# Analyze error patterns using the demo predictions\n",
    "error_analysis = analyze_error_patterns_with_demo_predictions(\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    y_pred=demo_predictions,\n",
    "    plate_sizes=[box[2] * box[3] for box in y_val]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c634eea",
   "metadata": {},
   "source": [
    "## 8. License Plate Detection on New Images\n",
    "\n",
    "Finally, let's use our model to detect license plates in new images. We'll use the `detect_license_plate` function\n",
    "from our main module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6888af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration purposes, we'll use a sample image from our dataset\n",
    "if len(df) > 0:\n",
    "    sample_img_path = df.iloc[10][\"image_path\"]\n",
    "\n",
    "    # In a real scenario, you would use a trained model\n",
    "    # model = load_and_prepare_model('license_plate_detector.h5')\n",
    "\n",
    "    # For demo purposes, we'll create a function to simulate detection\n",
    "    def demo_detect_license_plate(image_path):\n",
    "        \"\"\"Simulate license plate detection for demonstration\"\"\"\n",
    "        # Load image\n",
    "        img = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        orig_h, orig_w = img_rgb.shape[:2]\n",
    "        \n",
    "        # Get ground truth from dataset if available\n",
    "        file_name = os.path.basename(image_path)\n",
    "        matched_rows = df[df[\"image_path\"].str.contains(file_name)]\n",
    "        \n",
    "        if len(matched_rows) > 0:\n",
    "            # Use ground truth with small random offset\n",
    "            row = matched_rows.iloc[0]\n",
    "            x, y, w, h = row[\"x\"], row[\"y\"], row[\"w\"], row[\"h\"]\n",
    "            \n",
    "            # Add some noise to simulate prediction\n",
    "            noise_factor = 0.1\n",
    "            x += int(np.random.normal(0, w * noise_factor))\n",
    "            y += int(np.random.normal(0, h * noise_factor))\n",
    "            w += int(np.random.normal(0, w * noise_factor))\n",
    "            h += int(np.random.normal(0, h * noise_factor))\n",
    "            \n",
    "            # Ensure values are valid\n",
    "            x = max(0, min(x, orig_w - 10))\n",
    "            y = max(0, min(y, orig_h - 10))\n",
    "            w = max(10, min(w, orig_w - x))\n",
    "            h = max(10, min(h, orig_h - y))\n",
    "        else:\n",
    "            # Generate random detection\n",
    "            x = int(orig_w * 0.4)\n",
    "            y = int(orig_h * 0.4)\n",
    "            w = int(orig_w * 0.2)\n",
    "            h = int(orig_h * 0.1)\n",
    "        \n",
    "        # Draw detection on image\n",
    "        result_img = img_rgb.copy()\n",
    "        cv2.rectangle(result_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Display result\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(result_img)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"License Plate Detection (Demo)\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Extract plate region\n",
    "        plate_region = img_rgb[y:y + h, x:x + w]\n",
    "        \n",
    "        # Show extracted plate\n",
    "        plt.figure(figsize=(6, 2))\n",
    "        plt.imshow(plate_region)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Extracted License Plate\")\n",
    "        plt.show()\n",
    "        \n",
    "        return plate_region, [x, y, w, h]\n",
    "\n",
    "    # Detect license plate in sample image\n",
    "    demo_detect_license_plate(sample_img_path)\n",
    "else:\n",
    "    print(\"No images available for demonstration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a84fa9a",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "This notebook demonstrated how to use the modular license plate detection framework. The modularization offers several benefits:\n",
    "\n",
    "1. **Code Organization**: Clear separation of concerns with different modules handling specific tasks\n",
    "2. **Reusability**: Functions can be reused across different projects and contexts\n",
    "3. **Maintainability**: Easier to maintain and debug code with well-defined interfaces\n",
    "4. **Extensibility**: New functionality can be added with minimal changes to existing code\n",
    "5. **Testability**: Functions with clear inputs and outputs are easier to test\n",
    "\n",
    "For a complete implementation, additional features could be added:\n",
    "\n",
    "- Implement more advanced augmentation techniques\n",
    "- Add support for other annotation formats\n",
    "- Integrate with OCR for license plate text recognition\n",
    "- Develop real-time detection pipeline using video input"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
