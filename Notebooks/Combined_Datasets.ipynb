{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be3d2e9f",
   "metadata": {},
   "source": [
    "# Combining DataV2 and DataV3 into Dataset_XML\n",
    "\n",
    "This notebook combines the XML-based license plate datasets (DataV2 and DataV3) into a single unified dataset called Dataset_XML.\n",
    "\n",
    "Both datasets use the same annotation format with bounding boxes defined as:\n",
    "- `xmin, ymin`: Top-left corner\n",
    "- `xmax, ymax`: Bottom-right corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a7c742b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\ULB\\MA1\\Proj\\PROJ-H419\\Car-plate-detection\\DataV2\\images with prefix v2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying v2 files: 100%|██████████| 433/433 [00:02<00:00, 200.67it/s]\n",
      "Copying v2 files: 100%|██████████| 433/433 [00:02<00:00, 200.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 433 files from DataV2\n",
      "Processing c:\\ULB\\MA1\\Proj\\PROJ-H419\\Car-plate-detection\\DataV3\\images with prefix v3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying v3 files: 100%|██████████| 207/207 [00:02<00:00, 73.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 207 files from DataV3\n",
      "\n",
      "Combined dataset created at c:\\ULB\\MA1\\Proj\\PROJ-H419\\Car-plate-detection\\Dataset_XML\n",
      "Total images: 640\n",
      "Total annotations: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Paths\n",
    "base_dir = r\"c:\\ULB\\MA1\\Proj\\PROJ-H419\\Car-plate-detection\"\n",
    "datav2_dir = os.path.join(base_dir, \"DataV2\")\n",
    "datav3_dir = os.path.join(base_dir, \"DataV3\")\n",
    "output_dir = os.path.join(base_dir, \"Dataset_XML\")\n",
    "output_images_dir = os.path.join(output_dir, \"images\")\n",
    "output_anno_dir = os.path.join(output_dir, \"annotations\")\n",
    "\n",
    "# Make sure output directories exist\n",
    "os.makedirs(output_images_dir, exist_ok=True)\n",
    "os.makedirs(output_anno_dir, exist_ok=True)\n",
    "\n",
    "# Function to copy and rename files\n",
    "def copy_files_with_prefixes(source_img_dir, source_anno_dir, prefix, is_same_dir=False):\n",
    "    \"\"\"\n",
    "    Copy files from source directories to output directories, adding a prefix to avoid name conflicts\n",
    "    \n",
    "    Args:\n",
    "        source_img_dir: Directory containing images\n",
    "        source_anno_dir: Directory containing annotations\n",
    "        prefix: Prefix to add to filenames\n",
    "        is_same_dir: If True, annotations and images are in the same directory\n",
    "    \"\"\"\n",
    "    print(f\"Processing {source_img_dir} with prefix {prefix}...\")\n",
    "    \n",
    "    # Find images\n",
    "    if is_same_dir:\n",
    "        source_files = [f for f in os.listdir(source_img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    else:\n",
    "        source_files = [f for f in os.listdir(source_img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    # Copy files\n",
    "    n_processed = 0\n",
    "    for file in tqdm(source_files, desc=f\"Copying {prefix} files\"):\n",
    "        # Get basename without extension\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        \n",
    "        # Source image path\n",
    "        img_path = os.path.join(source_img_dir, file)\n",
    "        \n",
    "        # Source annotation path\n",
    "        if is_same_dir:\n",
    "            anno_file = f\"{base_name}.xml\"\n",
    "            anno_path = os.path.join(source_anno_dir, anno_file)\n",
    "        else:\n",
    "            anno_file = f\"{base_name}.xml\"\n",
    "            anno_path = os.path.join(source_anno_dir, anno_file)\n",
    "        \n",
    "        # Skip if annotation doesn't exist\n",
    "        if not os.path.exists(anno_path):\n",
    "            print(f\"  Skipping {file} - no matching annotation\")\n",
    "            continue\n",
    "        \n",
    "        # Target paths with prefix\n",
    "        target_img_file = f\"{prefix}_{file}\"\n",
    "        target_anno_file = f\"{prefix}_{base_name}.xml\"\n",
    "        \n",
    "        target_img_path = os.path.join(output_images_dir, target_img_file)\n",
    "        target_anno_path = os.path.join(output_anno_dir, target_anno_file)\n",
    "        \n",
    "        # Copy image\n",
    "        shutil.copy2(img_path, target_img_path)\n",
    "        \n",
    "        # Update XML with new filename before copying\n",
    "        try:\n",
    "            tree = ET.parse(anno_path)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # Update filename in XML\n",
    "            filename_elem = root.find('filename')\n",
    "            if filename_elem is not None:\n",
    "                filename_elem.text = target_img_file\n",
    "            \n",
    "            # Update path in XML if it exists\n",
    "            path_elem = root.find('path')\n",
    "            if path_elem is not None:\n",
    "                path_elem.text = target_img_path\n",
    "            \n",
    "            # Write updated XML to target\n",
    "            tree.write(target_anno_path)\n",
    "            n_processed += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing XML {anno_path}: {e}\")\n",
    "    \n",
    "    return n_processed\n",
    "\n",
    "# Process DataV2\n",
    "datav2_images = os.path.join(datav2_dir, \"images\")\n",
    "datav2_annotations = os.path.join(datav2_dir, \"annotations\")\n",
    "\n",
    "if os.path.exists(datav2_images) and os.path.exists(datav2_annotations):\n",
    "    n_v2 = copy_files_with_prefixes(datav2_images, datav2_annotations, \"v2\", is_same_dir=False)\n",
    "    print(f\"Processed {n_v2} files from DataV2\")\n",
    "else:\n",
    "    print(\"DataV2 directories not found\")\n",
    "\n",
    "# Process DataV3\n",
    "datav3_images = os.path.join(datav3_dir, \"images\")\n",
    "\n",
    "if os.path.exists(datav3_images):\n",
    "    n_v3 = copy_files_with_prefixes(datav3_images, datav3_images, \"v3\", is_same_dir=True)\n",
    "    print(f\"Processed {n_v3} files from DataV3\")\n",
    "else:\n",
    "    print(\"DataV3 directory not found\")\n",
    "\n",
    "# Count total files in output directory\n",
    "output_images = len([f for f in os.listdir(output_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "output_annotations = len([f for f in os.listdir(output_anno_dir) if f.lower().endswith('.xml')])\n",
    "\n",
    "print(f\"\\nCombined dataset created at {output_dir}\")\n",
    "print(f\"Total images: {output_images}\")\n",
    "print(f\"Total annotations: {output_annotations}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
