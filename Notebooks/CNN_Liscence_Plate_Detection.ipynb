{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "932a6a7e",
   "metadata": {},
   "source": [
    "# License Plate Detection Using Refactored Code\n",
    "\n",
    "This notebook has been updated to use the refactored license plate detection code. The code has been reorganized into a structured Python package with separate modules for different functionalities:\n",
    "\n",
    "- **data**: Data loading and preprocessing, augmentation\n",
    "- **models**: Neural network architectures and custom loss functions\n",
    "- **train**: Training utilities and learning rate scheduling\n",
    "- **evaluation**: Model evaluation and error analysis\n",
    "- **utils**: Visualization and analysis tools\n",
    "- **main**: Main functionality for detecting license plates\n",
    "\n",
    "Using this modular structure improves code organization, reusability, and maintainability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aee79a4a839067f",
   "metadata": {
    "id": "6aee79a4a839067f"
   },
   "source": [
    "# License Plate Detection with Refactored Code\n",
    "\n",
    "This notebook demonstrates how to use the refactored license plate detection code organized as a Python package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd4a43",
   "metadata": {},
   "source": [
    "# Step1: Data load and data exploration\n",
    "Here we will load the dataset and plot a image and it's corresponding bounding box of the plate in order to check that it matches the actual licence plate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e528036b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "e528036b",
    "outputId": "942816a5-178f-4eeb-e6be-2a06b07d2850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\ULB\\MA1\\Proj\\PROJ-H419\\Car-plate-detection\\Notebooks\n",
      "Project root: c:\\ULB\\MA1\\Proj\\PROJ-H419\\Car-plate-detection\n",
      "Project root added to path: c:\\ULB\\MA1\\Proj\\PROJ-H419\\Car-plate-detection\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'visualize_prediction' from 'license_plate_detection.utils.visualization' (c:\\ULB\\MA1\\Proj\\PROJ-H419\\Car-plate-detection\\license_plate_detection\\utils\\visualization.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlicense_plate_detection\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdetector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_license_plate_detector, create_enhanced_license_plate_detector\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlicense_plate_detection\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlosses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m enhanced_iou_metric, combined_detection_loss, giou_loss\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlicense_plate_detection\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_model, save_model\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlicense_plate_detection\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_lr_scheduler  \u001b[38;5;66;03m# Using correct function name\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlicense_plate_detection\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate_license_plate_detection, evaluate_model_comprehensive\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ULB\\MA1\\Proj\\PROJ-H419\\Car-plate-detection\\license_plate_detection\\__init__.py:29\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlicense_plate_detection\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     get_data_path,\n\u001b[32m     18\u001b[39m     load_dataset,\n\u001b[32m     19\u001b[39m     preprocess_dataset,\n\u001b[32m     20\u001b[39m     split_dataset\n\u001b[32m     21\u001b[39m )\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlicense_plate_detection\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlosses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     24\u001b[39m     enhanced_iou_metric,\n\u001b[32m     25\u001b[39m     combined_detection_loss,\n\u001b[32m     26\u001b[39m     giou_loss\n\u001b[32m     27\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlicense_plate_detection\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     30\u001b[39m     visualize_prediction,\n\u001b[32m     31\u001b[39m     visualize_batch_predictions,\n\u001b[32m     32\u001b[39m     plot_training_history\n\u001b[32m     33\u001b[39m )\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Import entry points\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlicense_plate_detection\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     37\u001b[39m     load_and_prepare_data,\n\u001b[32m     38\u001b[39m     create_model_by_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     predict\n\u001b[32m     42\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'visualize_prediction' from 'license_plate_detection.utils.visualization' (c:\\ULB\\MA1\\Proj\\PROJ-H419\\Car-plate-detection\\license_plate_detection\\utils\\visualization.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Check if running in Colab\n",
    "import importlib.util\n",
    "IN_COLAB = importlib.util.find_spec(\"google.colab\") is not None\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current directory: {current_dir}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Add project root to path to ensure imports work correctly\n",
    "    project_root = os.path.join(current_dir, \"Car-plate-detection\")\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Project root added to path: {project_root}\")\n",
    "    DATA_PATH = Path(project_root+\"/Dataset\")\n",
    "else:\n",
    "    # If not in Colab, set the project root to the current working directory's parent\n",
    "    project_root = Path(os.getcwd()).parent\n",
    "    print(f\"Project root: {project_root}\")\n",
    "    # Add project root to path to fix import errors\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(f\"Project root added to path: {project_root}\")\n",
    "    DATA_PATH = project_root / \"Dataset\"\n",
    "\n",
    "# Import our refactored modules\n",
    "from license_plate_detection.data.loader import get_data_path, load_dataset, preprocess_dataset, split_dataset\n",
    "# Using functions from existing modules instead of importing from modules that may not exist yet\n",
    "from license_plate_detection.data.augmentation import augment_data, visualize_augmentation\n",
    "from license_plate_detection.models.detector import create_license_plate_detector, create_enhanced_license_plate_detector\n",
    "from license_plate_detection.models.losses import enhanced_iou_metric, combined_detection_loss, giou_loss\n",
    "from license_plate_detection.train.trainer import train_model, save_model\n",
    "from license_plate_detection.train.scheduler import create_lr_scheduler  # Using correct function name\n",
    "from license_plate_detection.evaluation.evaluator import evaluate_license_plate_detection, evaluate_model_comprehensive\n",
    "from license_plate_detection.evaluation.error_analysis import analyze_predictions  # Use existing analysis function\n",
    "from license_plate_detection.utils.visualization import visualize_prediction, plot_training_history as visualize_training_history\n",
    "from license_plate_detection.utils.analysis import analyze_error_patterns\n",
    "from license_plate_detection.main import detect_license_plate, load_and_prepare_model\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Define paths to images and annotations folders\n",
    "IMAGES_PATH = DATA_PATH / \"images\"\n",
    "ANNOTATIONS_PATH = DATA_PATH / \"annotations\"\n",
    "\n",
    "# Check if the dataset paths exist\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"DATA_PATH does not exist: {DATA_PATH}\\n\"\n",
    "                            \"Please check the path or create the folder and add your data.\")\n",
    "if not IMAGES_PATH.exists():\n",
    "    raise FileNotFoundError(f\"IMAGES_PATH does not exist: {IMAGES_PATH}\")\n",
    "if not ANNOTATIONS_PATH.exists():\n",
    "    raise FileNotFoundError(f\"ANNOTATIONS_PATH does not exist: {ANNOTATIONS_PATH}\")\n",
    "\n",
    "print(f\"Found dataset with XML annotations format\")\n",
    "print(f\"Images directory: {IMAGES_PATH}\")\n",
    "print(f\"Annotations directory: {ANNOTATIONS_PATH}\")\n",
    "\n",
    "# Prepare a list to collect the dataset records\n",
    "dataset = []\n",
    "\n",
    "# 1) Loop through all files in the annotations folder\n",
    "for file in ANNOTATIONS_PATH.iterdir():\n",
    "    if file.suffix == \".xml\":\n",
    "        tree = ET.parse(file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for member in root.findall('object'):\n",
    "            img_name = root.find('filename').text  # Get filename from root, not member\n",
    "            img_path = IMAGES_PATH / img_name\n",
    "\n",
    "            if not img_path.exists():\n",
    "                print(f\"Image not found for annotation: {img_name}\")\n",
    "                continue\n",
    "\n",
    "            x = int(member.find('bndbox/xmin').text)\n",
    "            y = int(member.find('bndbox/ymin').text)\n",
    "            w = int(member.find('bndbox/xmax').text) - x\n",
    "            h = int(member.find('bndbox/ymax').text) - y\n",
    "\n",
    "            # Try to find plate_text in different elements, handling possible missing elements\n",
    "            name_elem = member.find('n')\n",
    "            if name_elem is not None:\n",
    "                plate_text = name_elem.text\n",
    "            else:\n",
    "                license_text_elem = member.find('license_text')\n",
    "                if license_text_elem is not None:\n",
    "                    plate_text = license_text_elem.text\n",
    "                else:\n",
    "                    plate_text = \"Unknown\"  # Default if no text found\n",
    "\n",
    "            dataset.append({\n",
    "                \"image_path\": str(img_path),\n",
    "                \"x\": x,\n",
    "                \"y\": y,\n",
    "                \"w\": w,\n",
    "                \"h\": h,\n",
    "                \"plate_text\": plate_text\n",
    "            })\n",
    "\n",
    "# 2) Convert to DataFrame\n",
    "df = pd.DataFrame(dataset)\n",
    "print(f\"Loaded {len(df)} annotated images.\")\n",
    "\n",
    "# 3) Visualize a sample - only if we have at least one image\n",
    "if len(df) > 0:\n",
    "    # Take first sample or specific index if available\n",
    "    sample_idx = min(199, len(df) - 1)  # Ensure index exists\n",
    "    sample = df.iloc[sample_idx]\n",
    "    img = cv2.imread(sample[\"image_path\"])\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Draw bounding box\n",
    "    x, y, w, h = sample[\"x\"], sample[\"y\"], sample[\"w\"], sample[\"h\"]\n",
    "    cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(f\"Plate: {sample['plate_text']}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No images loaded. Please check dataset path and XML format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7635953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths to dataset\n",
    "data_path = get_data_path()\n",
    "IMAGES_PATH = data_path / \"images\"\n",
    "ANNOTATIONS_PATH = data_path / \"annotations\"\n",
    "\n",
    "print(f\"Data path: {data_path}\")\n",
    "print(f\"Images directory: {IMAGES_PATH}\")\n",
    "print(f\"Annotations directory: {ANNOTATIONS_PATH}\")\n",
    "\n",
    "# Load the dataset using the refactored function\n",
    "df = load_dataset(ANNOTATIONS_PATH, IMAGES_PATH)\n",
    "print(f\"Loaded {len(df)} annotated images.\")\n",
    "\n",
    "# Show sample data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c033a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample image from the dataset\n",
    "if len(df) > 0:\n",
    "    # Take a specific sample or a random one\n",
    "    sample_idx = min(42, len(df) - 1)  # Ensure index exists\n",
    "    sample = df.iloc[sample_idx]\n",
    "    \n",
    "    # Load the image\n",
    "    img = cv2.imread(sample[\"image_path\"])\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Draw bounding box\n",
    "    x, y, w, h = sample[\"x\"], sample[\"y\"], sample[\"w\"], sample[\"h\"]\n",
    "    cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img_rgb)\n",
    "    if \"plate_text\" in sample and sample[\"plate_text\"] != \"Unknown\":\n",
    "        plt.title(f\"Plate: {sample['plate_text']}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No images loaded. Please check dataset path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399cea25",
   "metadata": {},
   "source": [
    "# Step 2: Data Preprocessing\n",
    "\n",
    "This will resize images and normalize bounding box coordinates and augment the data in order to arrive at 5K images and ensure a good training for the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f467bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset using the refactored function\n",
    "IMAGE_SIZE = (224, 224)  # Target size for CNN\n",
    "X, y = preprocess_dataset(df, image_size=IMAGE_SIZE)\n",
    "\n",
    "print(f\"Processed {len(X)} images.\")\n",
    "print(\"Image shape:\", X[0].shape)\n",
    "print(\"Sample bounding box (normalized):\", y[0])\n",
    "\n",
    "# Visualize a processed sample\n",
    "def visualize_processed_sample(index=0):\n",
    "    if index >= len(X) or index < 0:\n",
    "        print(f\"Index {index} is out of bounds.\")\n",
    "        return\n",
    "        \n",
    "    img_normalized = X[index]\n",
    "    bbox_norm = y[index]\n",
    "    original_row = df.iloc[index]\n",
    "    \n",
    "    # Load the original image\n",
    "    img_original = cv2.imread(original_row[\"image_path\"])\n",
    "    img_original = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Draw original bbox\n",
    "    x_orig, y_orig, w_orig, h_orig = original_row[\"x\"], original_row[\"y\"], original_row[\"w\"], original_row[\"h\"]\n",
    "    img_original_vis = img_original.copy()\n",
    "    cv2.rectangle(img_original_vis, (x_orig, y_orig), (x_orig + w_orig, y_orig + h_orig), (255, 0, 0), 2)\n",
    "    \n",
    "    # Prepare normalized image\n",
    "    img_vis = (img_normalized * 255).astype(np.uint8).copy()\n",
    "    x_norm = int(bbox_norm[0] * IMAGE_SIZE[0])\n",
    "    y_norm = int(bbox_norm[1] * IMAGE_SIZE[1])\n",
    "    w_norm = int(bbox_norm[2] * IMAGE_SIZE[0])\n",
    "    h_norm = int(bbox_norm[3] * IMAGE_SIZE[1])\n",
    "    cv2.rectangle(img_vis, (x_norm, y_norm), (x_norm + w_norm, y_norm + h_norm), (0, 255, 0), 2)\n",
    "    \n",
    "    # Plot side-by-side\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    axs[0].imshow(img_original_vis)\n",
    "    axs[0].set_title('Original Image with Original BBox')\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    axs[1].imshow(img_vis)\n",
    "    axs[1].set_title('Normalized & Resized Image with BBox')\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show a processed sample\n",
    "visualize_processed_sample(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a30075b",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "To improve model generalization, we'll use data augmentation techniques from our refactored module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b369857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data augmentation\n",
    "X_aug, y_aug = augment_data(X, y, augmentation_factor=4)\n",
    "\n",
    "# Visualize some augmented samples\n",
    "visualize_augmentation(X, y, X_aug, y_aug, num_samples=4)\n",
    "\n",
    "# 2. Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = split_dataset(X_aug, y_aug, test_size=0.2, random_state=42)\n",
    "print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a4b9a",
   "metadata": {},
   "source": [
    "# Step 3: Model Architecture definition\n",
    "\n",
    "Now we'll create the license plate detection model. We will try 5 different architectures:\n",
    "1. Basic License Plate Detector\n",
    "2. Enhanced License Plate Detector\n",
    "3. MobileNetV2-Based License Plate Detector\n",
    "4. EfficientNet-Based License Plate Detector\n",
    "5. Optimized License Plate Detector (CNN_Liscence_Plate_Detection.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac37cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the enhanced model from the refactored module\n",
    "model = create_enhanced_license_plate_detector(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# Print model size information\n",
    "trainable_count = np.sum([keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "non_trainable_count = np.sum([keras.backend.count_params(w) for w in model.non_trainable_weights])\n",
    "print(f'Total parameters: {trainable_count + non_trainable_count:,}')\n",
    "print(f'Trainable parameters: {trainable_count:,}')\n",
    "print(f'Non-trainable parameters: {non_trainable_count:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97722d2d",
   "metadata": {},
   "source": [
    "# Step 4: Model Training\n",
    "\n",
    "Now we'll compile and train the model using our custom loss functions and  learning rate scheduling.\n",
    "\n",
    "We have different posibilitis for the training:\n",
    "1. Create callbacks for model training\n",
    "2. Train a license plate detection model\n",
    "3. Train a license plate detection model with on-the-fly data augmentation\n",
    "4. Save a trained model\n",
    "\n",
    "We have different possibilitis for the loss function:\n",
    "1. Mean IoU loss\n",
    "2. Combined detection loss (iou loss * 0.5 + position loss * 0.3 + size loss * 0.2)\n",
    "3. GIoU loss\n",
    "4. Focal loss\n",
    "\n",
    "We have as well different learning rate scheduelers:\n",
    "1. Cosine decay learning rate scheduler\n",
    "2. Step decay learning rate scheduler\n",
    "3. step_decay_scheduler : Creates a step decay learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a985f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with custom loss functions from refactored module\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=combined_detection_loss,\n",
    "    metrics=[enhanced_iou_metric, giou_loss]\n",
    ")\n",
    "\n",
    "# Create callbacks using refactored modules\n",
    "callbacks = [\n",
    "    # Learning rate scheduler\n",
    "    CosineAnnealingWarmRestarts(\n",
    "        initial_lr=0.001,\n",
    "        min_lr=1e-6,\n",
    "        cycles=5,\n",
    "        cycle_length=10\n",
    "    ),\n",
    "    \n",
    "    # Early stopping\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_enhanced_iou_metric',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        mode='max'\n",
    "    ),\n",
    "    \n",
    "    # Model checkpoint\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'enhanced_license_plate_detector.h5',\n",
    "        monitor='val_enhanced_iou_metric',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Train model (commented out to avoid accidental training)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Visualize training history using refactored function\n",
    "visualize_training_history(history)\n",
    "\n",
    "# Save model using refactored function\n",
    "save_model(model, 'license_plate_detector_final.h5')\n",
    "\n",
    "\n",
    "# Alternatively, use the train_model function from our refactored module\n",
    "\"\"\"\n",
    "history, model = train_model(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    loss_function=combined_detection_loss,\n",
    "    metrics=[enhanced_iou_metric],\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca629d",
   "metadata": {},
   "source": [
    "# Step 6: Model Evaluation\n",
    "\n",
    "Let's evaluate our model using the evaluation functions from our refactored module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f953c9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration purposes, generate demo predictions\n",
    "def generate_demo_predictions(model, X_val, y_val):\n",
    "    \"\"\"Generate plausible demo predictions for visualization purposes\"\"\"\n",
    "    # Get predictions from untrained model\n",
    "    random_preds = model.predict(X_val)\n",
    "    \n",
    "    # Make them somewhat reasonable by combining with ground truth\n",
    "    demo_preds = []\n",
    "    for i, (pred, gt) in enumerate(zip(random_preds, y_val)):\n",
    "        # Create a prediction that's a noisy version of ground truth\n",
    "        noise = np.random.normal(0, 0.1, 4)  # Add some noise\n",
    "        noisy_pred = gt + noise\n",
    "        \n",
    "        # Ensure values are in range [0, 1]\n",
    "        noisy_pred = np.clip(noisy_pred, 0, 1)\n",
    "        \n",
    "        # Make width and height reasonable\n",
    "        noisy_pred[2] = max(0.05, min(noisy_pred[2], 0.5))  # Width\n",
    "        noisy_pred[3] = max(0.05, min(noisy_pred[3], 0.3))  # Height\n",
    "        \n",
    "        demo_preds.append(noisy_pred)\n",
    "    \n",
    "    return np.array(demo_preds)\n",
    "\n",
    "# Generate demo predictions\n",
    "demo_predictions = generate_demo_predictions(model, X_val, y_val)\n",
    "\n",
    "# Run evaluation with demo predictions using the refactored evaluator\n",
    "# In a real scenario, you would use true model predictions\n",
    "#results = evaluate_license_plate_detection(model, X_val, y_val, demo_predictions)\n",
    "\n",
    "# You could also run a comprehensive evaluation\n",
    "comprehensive_results = evaluate_model_comprehensive(model, X_val, y_val, demo_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2756c8",
   "metadata": {},
   "source": [
    "# Step 7: Error Analysis\n",
    "\n",
    "Performs a detailed analysis of prediction errors to help you understand where and why your license plate detection model makes mistakes. This provides valuable insights for model improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3354d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze error patterns using the refactored module\n",
    "error_analysis = analyze_error_patterns(\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    y_pred=demo_predictions,\n",
    "    plate_sizes=[box[2] * box[3] for box in y_val]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f587187",
   "metadata": {},
   "source": [
    "## License Plate Detection\n",
    "\n",
    "Finally, let's use our model to detect license plates in new images using the refactored module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85055b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration purposes, use a sample image from our dataset\n",
    "if len(df) > 0:\n",
    "    sample_img_path = df.iloc[10][\"image_path\"]\n",
    "\n",
    "    # In a real scenario, you would use the refactored function with a trained model\n",
    "    # plate_region, bbox = detect_license_plate(sample_img_path, model, confidence_threshold=0.5)\n",
    "    \n",
    "    # For demo purposes, simulate detection\n",
    "    def demo_detect_license_plate(image_path):\n",
    "        \"\"\"Simulate license plate detection for demonstration\"\"\"\n",
    "        # Load image\n",
    "        img = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        orig_h, orig_w = img_rgb.shape[:2]\n",
    "        \n",
    "        # Get ground truth from dataset if available\n",
    "        file_name = os.path.basename(image_path)\n",
    "        matched_rows = df[df[\"image_path\"].str.contains(file_name)]\n",
    "        \n",
    "        if len(matched_rows) > 0:\n",
    "            # Use ground truth with small random offset\n",
    "            row = matched_rows.iloc[0]\n",
    "            x, y, w, h = row[\"x\"], row[\"y\"], row[\"w\"], row[\"h\"]\n",
    "            \n",
    "            # Add some noise to simulate prediction\n",
    "            noise_factor = 0.1\n",
    "            x += int(np.random.normal(0, w * noise_factor))\n",
    "            y += int(np.random.normal(0, h * noise_factor))\n",
    "            w += int(np.random.normal(0, w * noise_factor))\n",
    "            h += int(np.random.normal(0, h * noise_factor))\n",
    "            \n",
    "            # Ensure values are valid\n",
    "            x = max(0, min(x, orig_w - 10))\n",
    "            y = max(0, min(y, orig_h - 10))\n",
    "            w = max(10, min(w, orig_w - x))\n",
    "            h = max(10, min(h, orig_h - y))\n",
    "        else:\n",
    "            # Generate random detection\n",
    "            x = int(orig_w * 0.4)\n",
    "            y = int(orig_h * 0.4)\n",
    "            w = int(orig_w * 0.2)\n",
    "            h = int(orig_h * 0.1)\n",
    "        \n",
    "        # Draw detection on image\n",
    "        result_img = img_rgb.copy()\n",
    "        cv2.rectangle(result_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Display result\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(result_img)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"License Plate Detection (Demo)\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Extract plate region\n",
    "        plate_region = img_rgb[y:y + h, x:x + w]\n",
    "        \n",
    "        # Show extracted plate\n",
    "        plt.figure(figsize=(6, 2))\n",
    "        plt.imshow(plate_region)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Extracted License Plate\")\n",
    "        plt.show()\n",
    "        \n",
    "        return plate_region, [x, y, w, h]\n",
    "\n",
    "    # Detect license plate in sample image\n",
    "    demo_detect_license_plate(sample_img_path)\n",
    "else:\n",
    "    print(\"No images available for demonstration.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
